{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\n",
      "ERROR: No matching distribution found for pickle\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/NREL/alfabet.git@0.2.2\n",
      "  Cloning https://github.com/NREL/alfabet.git (to revision 0.2.2) to c:\\users\\80710\\appdata\\local\\temp\\pip-req-build-14iep16g\n",
      "  Resolved https://github.com/NREL/alfabet.git to commit 9942cbd6fceeed549e8126692b15bb135e103f5a\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from alfabet==0.2.2) (2.2.3)\n",
      "Requirement already satisfied: nfp>=0.3.6 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from alfabet==0.2.2) (0.3.12)\n",
      "Requirement already satisfied: tqdm in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from alfabet==0.2.2) (4.66.5)\n",
      "Requirement already satisfied: pooch in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from alfabet==0.2.2) (1.8.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from alfabet==0.2.2) (1.4.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from alfabet==0.2.2) (0.24.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from nfp>=0.3.6->alfabet==0.2.2) (1.26.4)\n",
      "Requirement already satisfied: networkx>2.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from nfp>=0.3.6->alfabet==0.2.2) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from pandas->alfabet==0.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from pandas->alfabet==0.2.2) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from pandas->alfabet==0.2.2) (2024.2)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from pooch->alfabet==0.2.2) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from pooch->alfabet==0.2.2) (24.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from pooch->alfabet==0.2.2) (2.32.3)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from scikit-learn->alfabet==0.2.2) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from scikit-learn->alfabet==0.2.2) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from tqdm->alfabet==0.2.2) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->alfabet==0.2.2) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from requests>=2.19.0->pooch->alfabet==0.2.2) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from requests>=2.19.0->pooch->alfabet==0.2.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from requests>=2.19.0->pooch->alfabet==0.2.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from requests>=2.19.0->pooch->alfabet==0.2.2) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/NREL/alfabet.git 'C:\\Users\\80710\\AppData\\Local\\Temp\\pip-req-build-14iep16g'\n",
      "  Running command git checkout -q 9942cbd6fceeed549e8126692b15bb135e103f5a\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/NREL/alfabet.git@0.2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.2\n"
     ]
    }
   ],
   "source": [
    "import alfabet\n",
    "print(alfabet.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rdkit\n",
    "import rdkit.Chem\n",
    "import rdkit.Chem.AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\json_utils.py:187: The name tf.Dimension is deprecated. Please use tf.compat.v1.Dimension instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:178: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:178: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from alfabet.drawing import draw_mol_outlier\n",
    "from alfabet.fragment import canonicalize_smiles\n",
    "from alfabet.neighbors import find_neighbor_bonds\n",
    "from alfabet.prediction import predict_bdes, check_input\n",
    "\n",
    "import networkx as nx\n",
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完全显示DataFrame所有行和列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bde_graph_selective_hs(smiles: str, bde_df) -> nx.Graph:\n",
    "    \"\"\"\n",
    "    Build a NetworkX graph from the *original (heavy-atom)* RDKit Mol:\n",
    "      - Keep all heavy-atom ring & skeleton bonds from the SMILES.\n",
    "      - Add new H-X bonds (i.e., only the hydrogens needed) when a row in bde_df indicates\n",
    "        a predicted bond that doesn't already exist in the heavy-atom Mol.\n",
    "    \n",
    "    bde_df is expected to have columns:\n",
    "       - start_atom, end_atom: integer indexes or placeholders\n",
    "       - bde_pred, bdfe_pred, etc.: predicted data for each bond\n",
    "       - possibly bond_index (optional)\n",
    "    \n",
    "    Steps:\n",
    "       1) Parse the SMILES without adding Hs (just once).\n",
    "       2) Build a base Nx graph with all heavy-atom nodes & edges.\n",
    "       3) Iterate over bde_df. If the row corresponds to an existing heavy–heavy bond,\n",
    "          update the Nx edge with predicted data. If the row corresponds to an H–X bond,\n",
    "          add the H node + edge and store the predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Parse the SMILES into an RDKit Mol (no AddHs)\n",
    "    base_mol = Chem.MolFromSmiles(smiles)\n",
    "    if base_mol is None:\n",
    "        # Handle parse error, e.g. return empty graph\n",
    "        return nx.Graph()\n",
    "\n",
    "    # 2. Create an Nx graph, optionally store the RDKit Mol for reference\n",
    "    G = nx.Graph(mol=base_mol)\n",
    "\n",
    "    # 3. Add heavy-atom nodes\n",
    "    #    We'll store:\n",
    "    #      - 'symbol': e.g. 'C', 'O', 'N', etc.\n",
    "    #      - 'rdkit_idx': the integer index assigned by RDKit\n",
    "    #    Feel free to store other attributes as well.\n",
    "    for atom in base_mol.GetAtoms():\n",
    "        atom_idx = atom.GetIdx()\n",
    "        G.add_node(atom_idx, \n",
    "                   symbol=atom.GetSymbol(),\n",
    "                   rdkit_idx=atom_idx)\n",
    "\n",
    "    # 4. Add edges for all heavy-atom bonds in the original (no-H) Mol\n",
    "    #    We won't attach any BDE predictions yet (set them to None).\n",
    "    #    We'll also store a default bond_index=None if desired.\n",
    "    for bond in base_mol.GetBonds():\n",
    "        a1 = bond.GetBeginAtomIdx()\n",
    "        a2 = bond.GetEndAtomIdx()\n",
    "        G.add_edge(a1, a2,\n",
    "                   bond_index=None,\n",
    "                   bde_pred=None,\n",
    "                   bdfe_pred=None)\n",
    "\n",
    "    # 5. Iterate over bde_df.  We'll assume the columns are something like:\n",
    "    #     start_atom, end_atom, bde_pred, bdfe_pred, bond_index, etc.\n",
    "    #    - For heavy–heavy predictions, update the existing edge with predicted data.\n",
    "    #    - For H–X predictions, add the new hydrogen node & edge if not present.\n",
    "    #    - This approach assumes that for an H–X bond, either start_atom or end_atom\n",
    "    #      is a placeholder for hydrogen or an integer representing \"H\" in your dataset.\n",
    "    for _, row in bde_df.iterrows():\n",
    "        s = row['start_atom']\n",
    "        e = row['end_atom']\n",
    "        \n",
    "        # Attempt to interpret s and e in the context of the base mol\n",
    "        # We'll use a simple rule:\n",
    "        #  - If the index is >= base_mol.GetNumAtoms(), treat it as \"this is a hydrogen\"\n",
    "        #  - Or you could have a special marker like -1 for hydrogen\n",
    "        #    (depends on how your data is structured)\n",
    "        \n",
    "        # We also store predicted data\n",
    "        bde_pred_value = row.get('bde_pred', None)\n",
    "        bdfe_pred_value = row.get('bdfe_pred', None)\n",
    "        bond_index_value = row.get('bond_index', None)\n",
    "        \n",
    "        # Convert them to integers if needed\n",
    "        # (In practice, you may need to handle missing or invalid indexes carefully)\n",
    "        \n",
    "        # We'll define a helper function to check if an index is \"heavy\" or \"hydrogen\"\n",
    "        def is_heavy(idx):\n",
    "            return (0 <= idx < base_mol.GetNumAtoms())\n",
    "        \n",
    "        # Determine the \"types\" of s and e\n",
    "        s_is_heavy = is_heavy(s)\n",
    "        e_is_heavy = is_heavy(e)\n",
    "\n",
    "        if s_is_heavy and e_is_heavy:\n",
    "            # This is a heavy–heavy bond.\n",
    "            # If it already exists in G, update attributes.\n",
    "            if G.has_edge(s, e):\n",
    "                # Just update the existing edge\n",
    "                G[s][e]['bde_pred'] = bde_pred_value\n",
    "                G[s][e]['bdfe_pred'] = bdfe_pred_value\n",
    "                G[s][e]['bond_index'] = bond_index_value\n",
    "            else:\n",
    "                # Possibly -?> no, not possible the bond doesn't exist in the original skeleton \n",
    "                # (this can happen if the SMILES didn't have it).\n",
    "                # Add it as a new edge. This is unusual, but let's handle it anyway.\n",
    "                G.add_edge(s, e,\n",
    "                           bond_index=bond_index_value,\n",
    "                           bde_pred=bde_pred_value,\n",
    "                           bdfe_pred=bdfe_pred_value)\n",
    "\n",
    "        else:\n",
    "            # At least one of them is a \"hydrogen\" or out-of-range index\n",
    "            # We'll figure out which one is the heavy atom and which is the hydrogen.\n",
    "            if s_is_heavy and not e_is_heavy:\n",
    "                heavy_idx, hydrogen_idx = s, e\n",
    "            elif e_is_heavy and not s_is_heavy:\n",
    "                heavy_idx, hydrogen_idx = e, s\n",
    "            else:\n",
    "                # Both are hydrogens or out-of-range, which might be invalid.\n",
    "                # For safety, just skip or handle error.\n",
    "                # Could print a warning, raise an exception, etc.\n",
    "                continue\n",
    "\n",
    "            # Step 1: ensure the hydrogen node is present in G\n",
    "            # We'll generate a unique node key for the H, e.g. \"H_{hydrogen_idx}\"\n",
    "            # or something that won't collide with integer-based heavy nodes.\n",
    "            # You could also store the actual integer if your system allows it.\n",
    "            h_node = f\"H_{hydrogen_idx}\"\n",
    "            if not G.has_node(h_node):\n",
    "                # Add the hydrogen node with minimal attributes\n",
    "                G.add_node(h_node,\n",
    "                           symbol='H',\n",
    "                           rdkit_idx=None)  # or some other placeholder\n",
    "\n",
    "            # Step 2: add the H–X bond or update if it already exists\n",
    "            # The heavy_idx is the integer from RDKit.\n",
    "            if not G.has_edge(heavy_idx, h_node):\n",
    "                G.add_edge(heavy_idx, h_node,\n",
    "                           bond_index=bond_index_value,\n",
    "                           bde_pred=bde_pred_value,\n",
    "                           bdfe_pred=bdfe_pred_value)\n",
    "            else:\n",
    "                # If it somehow exists, just update attributes\n",
    "                G[heavy_idx][h_node]['bde_pred'] = bde_pred_value\n",
    "                G[heavy_idx][h_node]['bdfe_pred'] = bdfe_pred_value\n",
    "                G[heavy_idx][h_node]['bond_index'] = bond_index_value\n",
    "\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_to_df(bde_graph: nx.Graph) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert the edges of bde_graph into a DataFrame with columns:\n",
    "      ['u', 'v', 'bond_index', 'graph_bde_pred', 'graph_bdfe_pred'].\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for u, v, data in bde_graph.edges(data=True):\n",
    "        rows.append({\n",
    "            'u': u,\n",
    "            'v': v,\n",
    "            'bond_index': data['bond_index'],\n",
    "            'graph_bde_pred': data.get('bde_pred', None),\n",
    "            'graph_bdfe_pred': data.get('bdfe_pred', None)\n",
    "        })\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_list = ['C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([C@@]2(CC3)C)CCCC)(C)C',\n",
    "       'C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([C@@]2(CC3)C)CCC(C)C)(C)C',\n",
    "       'C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([C@@]2(CC3)C)CC[C@@H](C)CC)(C)C',\n",
    "       'C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([C@@]2(CC3)C)CC[C@H](CCC)C)(C)C',\n",
    "       'C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([C@]2(C)CC3)CC[C@H](C)CCCCC)(C)C',\n",
    "       'C(CCC)C[C@H](C)CC[C@@H]1[C@H](CC[C@H]2[C@]1(CC[C@@H]3[C@@]2(CCCC3(C)C)C)C)C',\n",
    "       'C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([C@@]2(CC3)C)CC[C@@H](CCCC(C)C)C)(C)C',\n",
    "       'C(C[C@@H](CC[C@H]1[C@]3([C@H](CC[C@@H]1C)[C@]2(CCCC(C)(C)[C@@H]2CC3)C)C)C)CC(C)C',\n",
    "       '[C@]23(CC[C@@H]1[C@@](CCCC1(C)C)(C)[C@H]2CC[C@H]4[C@]3(CC[C@]5([C@@H]4CCC5)C)C)C',\n",
    "       '[C@]12(CC[C@@H]5[C@@]([C@H]1CC[C@H]3[C@@]2(C)CC[C@H]4[C@@]3(CCC4)C)(CCCC5(C)C)C)C',\n",
    "       'CC[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C',\n",
    "       'CCC[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C',\n",
    "       'CCC(C)[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C',\n",
    "       'CC[C@@H](C)[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C',\n",
    "       'CCCC(C)[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C',\n",
    "       'CCC[C@@H](C)[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C',\n",
    "       'CCCCC(C)[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C',\n",
    "       'CCCC[C@@H](C)[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C',\n",
    "       'CCCCCC(C)[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C',\n",
    "       'CCCCC[C@@H](C)[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "def quote(x):\n",
    "    return urllib.parse.quote(x, safe='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Molecule CC[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n",
      "WARNING:root:Molecule CCC[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n",
      "WARNING:root:Molecule CCC(C)[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n",
      "WARNING:root:Molecule CC[C@@H](C)[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n",
      "WARNING:root:Molecule CCCC(C)[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n",
      "WARNING:root:Molecule CCC[C@@H](C)[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n",
      "WARNING:root:Molecule CCCCC(C)[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n",
      "WARNING:root:Molecule CCCC[C@@H](C)[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n",
      "WARNING:root:Molecule CCCCCC(C)[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n",
      "WARNING:root:Molecule CCCCC[C@@H](C)[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "graphs = []  # Optionally keep a list of graphs if you want them separately\n",
    "\n",
    "for smiles in smiles_list:\n",
    "    # 1) Canonicalize and sanity-check input\n",
    "    can_smiles = canonicalize_smiles(smiles)\n",
    "    is_outlier, missing_atom, missing_bond = check_input(can_smiles)\n",
    "\n",
    "    # 2) Get DataFrame of predicted BDE/BDFE for each bond\n",
    "    bde_df = predict_bdes(can_smiles, draw=True)\n",
    "    bde_df['raw_smiles'] = smiles\n",
    "\n",
    "    # 3) Deduplicate and store any extra columns you like\n",
    "    bde_df = bde_df.drop_duplicates(['fragment1', 'fragment2']).reset_index(drop=True)\n",
    "    bde_df['smiles_link'] = bde_df.molecule.apply(quote)\n",
    "\n",
    "    # 4) Build a NetworkX graph containing predicted BDE/BDFE\n",
    "    bde_graph = create_bde_graph_selective_hs(can_smiles, bde_df)\n",
    "\n",
    "    # 5) (Optional) store the graph in the DataFrame if you want\n",
    "    #    the same graph for all rows (one per entire molecule)\n",
    "    bde_df['nx_graph'] = [bde_graph] * len(bde_df)\n",
    "\n",
    "    # 6) Append to your results\n",
    "    dfs.append(bde_df)\n",
    "    graphs.append(bde_graph)   # In case you want them in parallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all DataFrame results\n",
    "alfabet_results_022 = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x14916144040>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u                  44\n",
       "v                  44\n",
       "bond_index         27\n",
       "graph_bde_pred     27\n",
       "graph_bdfe_pred    27\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph_to_df(graphs[0])) - graph_to_df(graphs[0]).isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['u', 'v', 'bond_index', 'graph_bde_pred', 'graph_bdfe_pred'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Assuming graph_to_df is a function to convert the graph to a DataFrame\n",
    "df = graph_to_df(graphs[0])\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>bond_index</th>\n",
       "      <th>graph_bde_pred</th>\n",
       "      <th>graph_bdfe_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.382645</td>\n",
       "      <td>75.711853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>H_23</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.077187</td>\n",
       "      <td>91.049133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.872467</td>\n",
       "      <td>71.412849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>H_27</td>\n",
       "      <td>29.0</td>\n",
       "      <td>97.163109</td>\n",
       "      <td>87.689636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.041306</td>\n",
       "      <td>70.000275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>H_28</td>\n",
       "      <td>30.0</td>\n",
       "      <td>95.392189</td>\n",
       "      <td>86.257256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>83.115479</td>\n",
       "      <td>66.995270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>H_30</td>\n",
       "      <td>32.0</td>\n",
       "      <td>94.518456</td>\n",
       "      <td>84.748627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>H_32</td>\n",
       "      <td>34.0</td>\n",
       "      <td>93.767822</td>\n",
       "      <td>84.237808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>86.171143</td>\n",
       "      <td>71.943581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>H_33</td>\n",
       "      <td>35.0</td>\n",
       "      <td>93.715736</td>\n",
       "      <td>84.072701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>H_36</td>\n",
       "      <td>38.0</td>\n",
       "      <td>98.747505</td>\n",
       "      <td>89.695900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>H_37</td>\n",
       "      <td>39.0</td>\n",
       "      <td>95.855804</td>\n",
       "      <td>86.941345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>H_40</td>\n",
       "      <td>42.0</td>\n",
       "      <td>94.971001</td>\n",
       "      <td>85.988342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>H_41</td>\n",
       "      <td>43.0</td>\n",
       "      <td>86.859306</td>\n",
       "      <td>75.766243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>79.460541</td>\n",
       "      <td>64.253860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11</td>\n",
       "      <td>H_44</td>\n",
       "      <td>46.0</td>\n",
       "      <td>97.184883</td>\n",
       "      <td>88.282654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12</td>\n",
       "      <td>H_46</td>\n",
       "      <td>48.0</td>\n",
       "      <td>95.408737</td>\n",
       "      <td>86.714401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>H_47</td>\n",
       "      <td>49.0</td>\n",
       "      <td>92.920944</td>\n",
       "      <td>84.154495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>14</td>\n",
       "      <td>H_49</td>\n",
       "      <td>51.0</td>\n",
       "      <td>89.283226</td>\n",
       "      <td>79.903214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>15.0</td>\n",
       "      <td>82.408630</td>\n",
       "      <td>67.338509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16</td>\n",
       "      <td>H_52</td>\n",
       "      <td>54.0</td>\n",
       "      <td>98.126953</td>\n",
       "      <td>89.117233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>18</td>\n",
       "      <td>H_56</td>\n",
       "      <td>58.0</td>\n",
       "      <td>96.827782</td>\n",
       "      <td>87.840210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>19</td>\n",
       "      <td>H_59</td>\n",
       "      <td>61.0</td>\n",
       "      <td>95.608147</td>\n",
       "      <td>86.592361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>20</td>\n",
       "      <td>H_61</td>\n",
       "      <td>63.0</td>\n",
       "      <td>96.082130</td>\n",
       "      <td>87.054794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>21.0</td>\n",
       "      <td>79.644073</td>\n",
       "      <td>64.361122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>22</td>\n",
       "      <td>H_62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>97.762428</td>\n",
       "      <td>88.862091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     u     v  bond_index  graph_bde_pred  graph_bdfe_pred\n",
       "0    0     1         0.0       89.382645        75.711853\n",
       "1    0  H_23        25.0      100.077187        91.049133\n",
       "2    1     2         1.0       85.872467        71.412849\n",
       "3    1  H_27        29.0       97.163109        87.689636\n",
       "4    2     3         2.0       85.041306        70.000275\n",
       "5    2  H_28        30.0       95.392189        86.257256\n",
       "6    3     4         3.0       83.115479        66.995270\n",
       "7    3  H_30        32.0       94.518456        84.748627\n",
       "8    4     5         NaN             NaN              NaN\n",
       "9    4    10         NaN             NaN              NaN\n",
       "10   4  H_32        34.0       93.767822        84.237808\n",
       "11   5     6         5.0       86.171143        71.943581\n",
       "12   5     7         NaN             NaN              NaN\n",
       "13   5  H_33        35.0       93.715736        84.072701\n",
       "14   6  H_36        38.0       98.747505        89.695900\n",
       "15   7     8         NaN             NaN              NaN\n",
       "16   7  H_37        39.0       95.855804        86.941345\n",
       "17   8     9         NaN             NaN              NaN\n",
       "18   8  H_40        42.0       94.971001        85.988342\n",
       "19   9    10         NaN             NaN              NaN\n",
       "20   9    21         NaN             NaN              NaN\n",
       "21   9  H_41        43.0       86.859306        75.766243\n",
       "22  10    11        10.0       79.460541        64.253860\n",
       "23  10    12         NaN             NaN              NaN\n",
       "24  11  H_44        46.0       97.184883        88.282654\n",
       "25  12    13         NaN             NaN              NaN\n",
       "26  12  H_46        48.0       95.408737        86.714401\n",
       "27  13    14         NaN             NaN              NaN\n",
       "28  13  H_47        49.0       92.920944        84.154495\n",
       "29  14    15         NaN             NaN              NaN\n",
       "30  14    21         NaN             NaN              NaN\n",
       "31  14  H_49        51.0       89.283226        79.903214\n",
       "32  15    16        15.0       82.408630        67.338509\n",
       "33  15    17         NaN             NaN              NaN\n",
       "34  15    18         NaN             NaN              NaN\n",
       "35  16  H_52        54.0       98.126953        89.117233\n",
       "36  18    19         NaN             NaN              NaN\n",
       "37  18  H_56        58.0       96.827782        87.840210\n",
       "38  19    20         NaN             NaN              NaN\n",
       "39  19  H_59        61.0       95.608147        86.592361\n",
       "40  20    21         NaN             NaN              NaN\n",
       "41  20  H_61        63.0       96.082130        87.054794\n",
       "42  21    22        21.0       79.644073        64.361122\n",
       "43  22  H_62        64.0       97.762428        88.862091"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_to_df(graphs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加满的H的边的最大值 - 现在的边的数 就是没有输入的边"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "count = 0  # Initialize a counter\n",
    "for i in 'C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([C@@]2(CC3)C)CCCC)(C)C':\n",
    "    if i == 'C':  # Corrected colon\n",
    "        count += 1  # Increment the count\n",
    "print(count)  # Output the count\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1 : 23, edge1: 25\n",
      "node2: 23, edge2: 25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#mol = Chem.MolFromSmiles(smiles)\n",
    "#mol = Chem.AddHs(mol)\n",
    "# graph\n",
    "def mol_to_graph(mol):\n",
    "    graph = nx.Graph()\n",
    "    \n",
    "    # add nodes\n",
    "    for atom in mol.GetAtoms():\n",
    "        graph.add_node(\n",
    "            atom.GetIdx(),\n",
    "            label=atom.GetSymbol(),\n",
    "            atomic_num=atom.GetAtomicNum(),\n",
    "            is_aromatic=atom.GetIsAromatic()\n",
    "        )\n",
    "\n",
    "    # add edges\n",
    "    for bond in mol.GetBonds():\n",
    "        graph.add_edge(\n",
    "            bond.GetBeginAtomIdx(),\n",
    "            bond.GetEndAtomIdx(),\n",
    "            bond_type=bond.GetBondType()\n",
    "        )\n",
    "\n",
    "    return graph\n",
    "\n",
    "#graph = mol_to_graph(mol)\n",
    "\n",
    "smiles1 = 'CCCC[C@@H]1[C@@H](C)CC[C@H]2[C@@]1(C)CC[C@H]1C(C)(C)CCC[C@]21C'\n",
    "smiles2 = 'C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([C@@]2(CC3)C)CCCC)(C)C'\n",
    "\n",
    "mol1 = Chem.MolFromSmiles(smiles1)\n",
    "graph1 = mol_to_graph(mol1)\n",
    "num_nodes1 = graph1.number_of_nodes()\n",
    "num_edges1 = graph1.number_of_edges()\n",
    "\n",
    "mol2 = Chem.MolFromSmiles(smiles2)\n",
    "graph2 = mol_to_graph(mol2)\n",
    "num_nodes2 = graph2.number_of_nodes()\n",
    "num_edges2 = graph2.number_of_edges()\n",
    "\n",
    "print(f\"node1 : {num_nodes1}, edge1: {num_edges1}\")\n",
    "print(f\"node2: {num_nodes2}, edge2: {num_edges2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for idx, graph in enumerate(graphs):\n",
    "    with open(f\"gpickle_graph_{idx}.pkl\", 'wb') as f:\n",
    "        pickle.dump(graph, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "G = nx.path_graph(4)\n",
    "with open('test.gpickle', 'wb') as f:\n",
    "    pickle.dump(G, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('test.gpickle', 'rb') as f:\n",
    "    G = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alfabet-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
