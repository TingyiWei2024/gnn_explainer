{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from torch.utils.data import Dataset, Subset\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray, optuna\n",
    "from ray import tune, air\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MetaNet import MetaNet, BioDegDataset       # your module\n",
    "from train import build_loaders   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = BioDegDataset('df_cleaned.csv','.')\n",
    "#data = BioDegDatasetCached('biodataset_processed.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUPYTER CELL 3\n",
    "def train_one(config):\n",
    "    #gpu_id = int(ray.get_gpu_ids()[0])\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 1── loaders (with scaling applied inside)\n",
    "    train_ld, val_ld, test_ld= build_loaders(data,\n",
    "                                          val_mols=2,\n",
    "                                          test_mols=2,\n",
    "                                          seed=42,\n",
    "                                          bs_train=32,\n",
    "                                          bs_eval=64)\n",
    "\n",
    "    # 2── model\n",
    "    model = MetaNet(hidden=config[\"hidden\"],\n",
    "                    n_layers=config[\"layers\"]).to(device)\n",
    "    opt   = torch.optim.AdamW(model.parameters(),\n",
    "                              lr=config[\"lr\"],\n",
    "                              weight_decay=5e-4)\n",
    "    lossf = torch.nn.SmoothL1Loss()\n",
    "\n",
    "    best_val = -1e9\n",
    "    for epoch in range(500):\n",
    "        # ----- train ------------------------------------------------------\n",
    "        model.train()\n",
    "        for batch in train_ld:\n",
    "            batch = batch.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = lossf(model(batch), batch.y.squeeze())\n",
    "            loss.backward(); opt.step()\n",
    "       # ----- validation R² --------------------------------------------\n",
    "        model.eval(); y_val, p_val = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_ld:\n",
    "                batch = batch.to(device)\n",
    "                y_val.append(batch.y.cpu())\n",
    "                p_val.append(model(batch).cpu())\n",
    "        yv, pv = torch.cat(y_val), torch.cat(p_val)\n",
    "        val_r2 = 1 - ((yv - pv) ** 2).sum() / ((yv - yv.mean()) ** 2).sum()\n",
    "        best_val = max(best_val, val_r2.item())\n",
    "\n",
    "        # ----- test R²  (logged, not optimised) --------------------------\n",
    "        y_test, p_test = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_ld:\n",
    "                batch = batch.to(device)\n",
    "                y_test.append(batch.y.cpu())\n",
    "                p_test.append(model(batch).cpu())\n",
    "        yt, pt = torch.cat(y_test), torch.cat(p_test)\n",
    "        test_r2 = 1 - ((yt - pt) ** 2).sum() / ((yt - yt.mean()) ** 2).sum()\n",
    "            \n",
    "            \n",
    "\n",
    "        # report to Tune (for ASHA pruning & Optuna sampler)\n",
    "        tune.report({\"val_r2\": val_r2.item(),\"test_r2\": test_r2.item(), \"epoch\": epoch})\n",
    "\n",
    "        best = max(best_val, val_r2.item())\n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ray.shutdown()               # in case something is running\n",
    "ray.init(num_gpus=4, ignore_reinit_error=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_alg = OptunaSearch(\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    metric=\"val_r2\", mode=\"max\")\n",
    "\n",
    "scheduler = ASHAScheduler(metric=\"val_r2\", mode=\"max\",\n",
    "                          max_t=500, grace_period=30, reduction_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable = tune.with_resources(train_one, {\"gpu\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = tune.Tuner(\n",
    "    trainable,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        num_samples=500,\n",
    "        search_alg=search_alg,\n",
    "        scheduler=scheduler,\n",
    "        max_concurrent_trials=4,     # never exceed GPU count\n",
    "        reuse_actors=True,\n",
    "    ),\n",
    "    run_config=air.RunConfig(\n",
    "        name=\"metanet_demo_622\",\n",
    "        storage_path=os.path.abspath(\"ray_out\"),\n",
    "    ),\n",
    "    param_space={\n",
    "        \"hidden\": tune.choice([32, 64, 128,256]),\n",
    "        \"layers\": tune.choice([3, 4, 5,6,8,10]),\n",
    "        \"lr\":     tune.loguniform(1e-4, 3e-3),\n",
    "        #\"trial_seed\": tune.randint(0, 2**31 - 1),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tuner.fit()\n",
    "print(\"Best R²:\", analysis.get_best_result(\"val_r2\", \"max\").metrics[\"val_r2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
